{"metadata":{"kernelspec":{"name":"python37364bit373pyenv12eac4732f2b43a1b4568d3c81d03fef","display_name":"Python 3.7.3 64-bit ('3.7.3': pyenv)"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"metadata":{"interpreter":{"hash":"3ba36e87d5787d7317c76d99599e28c0f58c1f07f56e5c57767c8fb8cbccb865"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":["# ReadMe\n","\n","The code below was written for the UNSW Data Science Society Blog by Julian Garratt.\n","\n","Blog Post: Trading Stocks Based on Sentiment\n","\n","Note: No need to change any code unless stated otherwise (e.g. to change certain parameters)"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","source":["# Downloaded any other libraries here\n","!pip install newsapi-python\n","!pip install openpyxl\n","!pip install yahoo_fin\n","!pip install nltk\n","!pip install xlrd"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Libraries\n","import numpy as np \n","import pandas as pd \n","import requests\n","import re\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import seaborn as sns\n","from matplotlib import pyplot as plt"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# IMPORTANT: Get API Key (free) at https://newsapi.org/ \n","from newsapi import NewsApiClient\n","newsapi = NewsApiClient(api_key='INSERT API KEY')\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","from_param = choose starting date to scrap news\n","to = choose ending date\n","Other parameters don't need to be changed.\n","\"\"\"\n","every_headline = newsapi.get_everything(q='asx',\n","                                         sources=\"abc-news-au\",\n","                                         from_param = \"2021-03-20\",\n","                                         to = \"2021-03-22\",\n","                                         sort_by=\"relevancy\",\n","                                         language='en')\n","print(\"Done: {} results found\".format(every_headline[\"totalResults\"]))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Map ASX companies to a list of tuples [(company, code),...]\n","asx_mapping = pd.read_excel(\"asx_code_to_company.xlsx\", engine='openpyxl')\n","asx_mapping.Company = asx_mapping.Company.str.replace(\" ltd\", \"\", case = False)\n","asx_companies = list(zip(asx_mapping.Company.str.lower().values,asx_mapping.Code.values))\n","asx_companies[:10]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","n_urls can be changed to be greater than or less that 3 (as long as there exists more than 3 scraped news articles)\n","\"\"\"\n","\n","# Extract only content from \"n\" urls from the news api call (i.e. get rid of unimportant stuff e.g. javascript)\n","def get_content(n_urls):\n","    content = []\n","    \n","    for n in range(n_urls):\n","        # Get html of most relevant news article\n","        r = requests.get(every_headline[\"articles\"][n][\"url\"])\n","        text = r.text\n","        matches = [(m.start(0), m.end(0)) for m in re.finditer(\"{\\\"type\\\":\\\"text\\\",\\\"content\\\":\\\"(.*?)\\\"}\", text)]\n","\n","        for start, end in matches:\n","            content.append(eval(text[start:end])[\"content\"])\n","    \n","    return content\n","\n","content = get_content(3)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create dict of {Company : news about company, ...}\n","company_news_dict = {}\n","for company, code in asx_companies:\n","    r_company = re.compile(fr\"\\b({str(company)})\\b\")\n","    r_code = re.compile(fr\"\\b({str(code)})\\b\")\n","    company_news_dict[str(code)] = [line for line in content if r_company.search(line.lower()) or r_code.search(line)]\n","\n","# Remove values where a company has no news\n","keys_to_remove = []\n","for key in company_news_dict.keys():\n","    if not company_news_dict[key]:\n","        keys_to_remove.append(key)\n","\n","for keys in keys_to_remove:\n","    company_news_dict.pop(keys)\n","\n","company_news_dict"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate sentiment score for each company and create dict of {code : mean sentiment...}\n","sid = SentimentIntensityAnalyzer()\n","\n","def polarity_score(sentence, sid):\n","    sentiment_dict = sid.polarity_scores(sentence)\n","    return sentiment_dict[\"compound\"]\n","\n","asx_sentiment_dict = {}\n","for code in company_news_dict.keys():\n","    sentiment = []\n","    for sentence in company_news_dict[code]:\n","        sentiment.append(polarity_score(sentence, sid))\n","\n","    mean_sentiment = sum(sentiment)/len(sentiment)\n","    asx_sentiment_dict[code] = mean_sentiment\n","\n","# remove ABC (ABC in this context does not stand for Australian Broadcasting Corporation) as it occurs frequently in ABC articles\n","asx_sentiment_dict.pop(\"ABC\", None) \n","asx_sentiment_dict"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Backtesting\n"],"metadata":{}},{"cell_type":"code","source":["from yahoo_fin.stock_info import get_data"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class backtest():\n","    \n","    def __init__(self, asx_sentiment_dict, capital, start_date, end_date):\n","        self.start_date = start_date\n","        self.end_date = end_date\n","        self.codes = [key for key in asx_sentiment_dict.keys() if asx_sentiment_dict[key] > 0]\n","        self.capital_per_share = capital / len(self.codes)\n","        self.capital = capital\n","        self.ticker_data_dict = self.get_ticker_data(asx_sentiment_dict)\n","        self.delta_time = len(list(self.ticker_data_dict.items())[0][1].index)\n","        self.init_value = self.get_init_value()\n","        \n","    def get_ticker_data(self, asx_sentiment_dict):\n","        ticker_data_dict = {}\n","        for code in asx_sentiment_dict.keys():\n","            if asx_sentiment_dict[code] > 0:\n","                ticker_data_dict[code] = get_data(\"{}.AX\".format(code), start_date = self.start_date, end_date = self.end_date)\n","        return ticker_data_dict\n","    \n","    def get_init_value(self):\n","        init_value = {}\n","        for code in self.codes:\n","            init_value[code] = self.capital_per_share / self.ticker_data_dict[code].open.iloc[0]\n","        return init_value\n","    \n","    def backtest(self):\n","        # Find value per day per share at open price\n","        for code in self.codes:\n","            self.ticker_data_dict[code][\"value\"] = self.ticker_data_dict[code].open * self.init_value[code]\n","        # Find total value of portfolio per day\n","        total_value_per_day = []\n","        for i in range(self.delta_time):\n","            value_per_share = []\n","            for code in self.codes:\n","                code_value = self.ticker_data_dict[code][\"value\"].iloc[i]\n","                value_per_share.append(code_value)\n","            total_value_per_day.append(sum(value_per_share))\n","        # Plot results\n","        print(\"Final Value = {:.2f}\".format(total_value_per_day[-1]))\n","        print(\"Gains/Losses = {:.2f}\".format(total_value_per_day[-1] - total_value_per_day[0]))\n","        sns.set(style='whitegrid', context='talk')\n","        sns.lineplot(x = list(self.ticker_data_dict.items())[0][1].index.to_list(), y = total_value_per_day)\n","        sns.despine()\n","        plt.axhline(y=self.capital, label = \"Baseline Capital\", color = \"red\", linestyle = \"--\")\n","        plt.xlabel(\"Date\")\n","        plt.ylabel(\"Value\")\n","        actual_start_date = pd.to_datetime(self.start_date, format=\"%m/%d/%Y\") - pd.DateOffset(1)\n","        actual_end_date = pd.to_datetime(self.end_date, format=\"%m/%d/%Y\") - pd.DateOffset(1)\n","        plt.title(\"Portfolio Value from {} to {}\".format(actual_start_date.strftime(\"%d/%m/%Y\"), actual_end_date.strftime(\"%d/%m/%Y\")))\n","        plt.xticks(rotation = 45)\n","        plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","capital = Initial value of the portfolio\n","start_date = Date to begin simulation\n","end_date = Date to end simulation\n","\"\"\"\n","\n","# Backtest strategy\n","# Dates structure: %m/%d/%Y (will always get data from: start_date & end_date minus 1)\n","backtester = backtest(asx_sentiment_dict, capital=100000, start_date=\"03/24/2021\", end_date=\"03/31/2021\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Executing this block of code will run the backtest and will plot the portfolio value over time and final metrics.\n","backtester.backtest()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}